{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 21:09:18.811247: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-07 21:09:18.851140: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9373] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-07 21:09:18.851173: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-07 21:09:18.852316: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1534] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-07 21:09:18.858759: I tensorflow/core/platform/cpu_feature_guard.cc:183] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples, davies_bouldin_score\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense,MaxPooling2D,Dropout,Flatten,BatchNormalization,Conv2D\n",
    "import tensorflow.keras.utils as utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and Visualizing Data\n",
    "Data is downloaded to home directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Kaggle instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: kagglehub in /home/ridgewayg/.local/lib/python3.10/site-packages (0.3.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from kagglehub) (24.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kagglehub) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub) (4.66.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (2024.2.2)\n",
      "Path to dataset files: /home/ridgewayg/.cache/kagglehub/datasets/jessicali9530/stanford-dogs-dataset/versions/2\n"
     ]
    }
   ],
   "source": [
    "!pip install kagglehub\n",
    "# This one takes 3 minutes\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"jessicali9530/stanford-dogs-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Loading data into the memory is not efficient since it doesn't have enough memory for that much data\n",
    "# Load filenames into dataframe instead\n",
    "\n",
    "images = []\n",
    "\n",
    "labels = []\n",
    "\n",
    "label_count = 0\n",
    "\n",
    "images_path = path + r\"/images/Images/\"\n",
    "\n",
    "for label in os.listdir(images_path):\n",
    "    label_path = images_path + label + \"/\"\n",
    "    label_count += 1\n",
    "    for file in os.listdir(label_path):\n",
    "        images.append(label_path + file)\n",
    "        labels.append(label.split('-')[1])\n",
    "\n",
    "df = pd.DataFrame({\"image_path\" : images, \"label\": labels})\n",
    "\n",
    "df = df[:1850:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of train data (1480, 2)\n",
      "The shape of test data (185, 2)\n",
      "The shape of validation data (185, 2)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_temp = train_test_split(df, test_size=0.2, stratify=df[\"label\"], random_state = 42)\n",
    "\n",
    "label_test_val = X_temp['label']\n",
    "\n",
    "# 10%.   10%\n",
    "X_test, X_val = train_test_split(X_temp, test_size=0.5, stratify=label_test_val, random_state = 42)\n",
    "\n",
    "print('The shape of train data',X_train.shape)\n",
    "print('The shape of test data',X_test.shape)\n",
    "print('The shape of validation data',X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "image_size = 224 # Size of the image\n",
    "image_channel = 3 # Colour scale (RGB)\n",
    "bat_size = 1 # Number of files/images processed at once\n",
    "classes = 10\n",
    "samples = len(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1480 validated image filenames belonging to 10 classes.\n",
      "Found 185 validated image filenames belonging to 10 classes.\n",
      "Found 185 validated image filenames belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# Applyingimage data gernerator to train and test data\n",
    "datagen = ImageDataGenerator(\n",
    "            validation_split=0.2,\n",
    "            rescale=1./255, # to bring the image range from 0..255 to 0..1\n",
    "            rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            zoom_range = 0, # randomly zoom image \n",
    "            width_shift_range=0,  # randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range=0,  # randomly shift images vertically (fraction of total height)\n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=False) # randomly flip images\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(X_train,\n",
    "                                                    x_col= 'image_path',\n",
    "                                                    y_col= 'label',\n",
    "                                                    batch_size = bat_size,\n",
    "                                                    target_size = (image_size,image_size),\n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                   )\n",
    "val_generator = datagen.flow_from_dataframe(X_val, \n",
    "                                                 x_col= 'image_path',\n",
    "                                                 y_col= 'label',\n",
    "                                                 batch_size = bat_size,\n",
    "                                                 target_size = (image_size,image_size),\n",
    "                                                 shuffle=False,\n",
    "                                                 class_mode=\"categorical\",\n",
    "                                                )\n",
    "\n",
    "test_generator = datagen.flow_from_dataframe(X_test, \n",
    "                                                  x_col= 'image_path',\n",
    "                                                  y_col= 'label',\n",
    "                                                  batch_size = bat_size,\n",
    "                                                  target_size = (image_size,image_size),\n",
    "                                                  shuffle=False,\n",
    "                                                  class_mode=\"categorical\",\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the data generator\n",
    "num_classes = len(test_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155.0\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
      "                                                                 \n",
      " global_average_pooling2d_2  (None, 512)               0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14719818 (56.15 MB)\n",
      "Trainable params: 5130 (20.04 KB)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "155/155 [==============================] - 5s 25ms/step - loss: 2.3533 - accuracy: 0.1226 - val_loss: 2.2482 - val_accuracy: 0.2387\n",
      "Epoch 2/10\n",
      "155/155 [==============================] - 3s 21ms/step - loss: 2.2885 - accuracy: 0.0774 - val_loss: 2.1580 - val_accuracy: 0.2645\n",
      "Epoch 3/10\n",
      "155/155 [==============================] - 3s 21ms/step - loss: 2.2094 - accuracy: 0.1806 - val_loss: 2.1127 - val_accuracy: 0.2516\n",
      "Epoch 4/10\n",
      "155/155 [==============================] - 3s 22ms/step - loss: 2.1181 - accuracy: 0.2387 - val_loss: 2.0650 - val_accuracy: 0.3097\n",
      "Epoch 5/10\n",
      "155/155 [==============================] - 3s 21ms/step - loss: 2.1309 - accuracy: 0.2129 - val_loss: 2.0079 - val_accuracy: 0.2581\n",
      "Epoch 6/10\n",
      "155/155 [==============================] - 3s 22ms/step - loss: 2.0539 - accuracy: 0.2387 - val_loss: 1.9474 - val_accuracy: 0.2968\n",
      "Epoch 7/10\n",
      "155/155 [==============================] - 3s 21ms/step - loss: 2.0481 - accuracy: 0.2387 - val_loss: 1.9445 - val_accuracy: 0.2774\n",
      "Epoch 8/10\n",
      "155/155 [==============================] - 3s 21ms/step - loss: 1.9930 - accuracy: 0.3097 - val_loss: 1.8822 - val_accuracy: 0.3677\n",
      "Epoch 9/10\n",
      "155/155 [==============================] - 3s 21ms/step - loss: 1.8842 - accuracy: 0.3484 - val_loss: 1.8331 - val_accuracy: 0.3806\n",
      "Epoch 10/10\n",
      "155/155 [==============================] - 3s 21ms/step - loss: 1.8083 - accuracy: 0.4000 - val_loss: 1.8407 - val_accuracy: 0.3548\n"
     ]
    }
   ],
   "source": [
    "trans_epochs = 10\n",
    "batch_size = 12\n",
    "steps = np.ceil(samples/batch_size) \n",
    "print(steps)\n",
    "\n",
    "\n",
    "\n",
    "inputs = keras.Input(shape=(image_size, image_size, image_channel))\n",
    "\n",
    "#VGG16 Base Model\n",
    "trans_base_model = keras.applications.VGG16(\n",
    "    weights = 'imagenet', \n",
    "    input_shape = (image_size, image_size, image_channel),\n",
    "    include_top=False)\n",
    "\n",
    "#freezing the base model\n",
    "trans_base_model.trainable = False\n",
    "\n",
    "#start building new model components on-top of base model\n",
    "x = trans_base_model(inputs, training = False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "output =  keras.layers.Dense(classes, activation = 'softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs, output)\n",
    "model.summary()\n",
    "\n",
    "#compiling model\n",
    "model.compile(optimizer='Adam', loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "\n",
    "#trans_base_model.trainable = True #overfitting preventi by turning this back on!\n",
    "model.compile(optimizer='adam',\n",
    "                      loss =  'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "#actual model training\n",
    "history = model.fit(train_generator,\n",
    "                   validation_data = val_generator,\n",
    "                   steps_per_epoch = steps,\n",
    "                   validation_steps = steps,\n",
    "                   epochs = trans_epochs)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
